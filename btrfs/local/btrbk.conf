# btrbk configuration for backing up /home/mjr to AWS
#
# This configuration manages multi-subvolume backups using btrbk.
# Each directory under /home/mjr is a separate btrfs subvolume with independent
# snapshot and retention policies.
#
# Prerequisites:
#   1. AWS infrastructure deployed: ../scripts/setup-aws.sh
#   2. Environment variables set: source ../aws_connection.env
#   3. SSH agent running (e.g., 1Password): SSH_AUTH_SOCK must be set
#   4. Directories converted to subvolumes: sudo ./create-subvolumes.py
#
# Usage:
#   # Source AWS connection details first:
#   source ../aws_connection.env
#
#   # With cleanup (recommended - removes git-ignored files from snapshots):
#   sudo -E ./btrbk-with-cleanup.sh -v -n run  # dry-run (recommended first!)
#   sudo -E ./btrbk-with-cleanup.sh -v run      # actual backup with cleanup
#
#   # Without cleanup (faster, but includes git artifacts in snapshots):
#   sudo -E btrbk -c /path/to/this/file -v -n run  # dry-run
#   sudo -E btrbk -c /path/to/this/file -v run      # actual backup
#   sudo -E btrbk -c /path/to/this/file snapshot    # create local snapshots only
#
# Note: Use sudo -E to preserve environment variables (SSH_AUTH_SOCK, BTRBK_AWS_*)

# --- Global Settings ---

# Timestamp format for snapshot names
# Options: long (default), short, long-iso, short-iso
# long format: YYYYMMDD-HHMM (e.g., 20250103-1430)
timestamp_format        long

# Snapshot retention policy
# Format: <hourly> <daily> <weekly> <monthly> <yearly>
# Examples:
#   "24h 7d 4w 6m" = keep 24 hourly, 7 daily, 4 weekly, 6 monthly snapshots
#   "no no 4w 12m" = keep only weekly and monthly
#   "14d" = keep 14 daily snapshots (no hourly, weekly, monthly, yearly)
#
# snapshot_preserve_min: Minimum snapshots to keep (regardless of age)
# snapshot_preserve: Retention policy for local snapshots
snapshot_preserve_min   latest
snapshot_preserve       14d 8w 12m

# Remote (AWS) backup retention
# More aggressive retention to save on EBS costs
# target_preserve_min: Minimum backups to keep on remote
# target_preserve: Retention policy for remote backups
target_preserve_min     latest
target_preserve         90d 52w 120m

# Snapshot directory (relative to volume)
# With volume /home/mjr, this creates /home/mjr/.snapshots/
# All subvolume snapshots will be stored in this single directory
snapshot_dir            .snapshots

# When to create snapshots
# Options: always, onchange, ondemand, no
#   always = always create snapshot (recommended for regular backups)
#   onchange = only create if source has changed since last snapshot
#   ondemand = only create when explicitly requested
snapshot_create         onchange

# Use incremental send/receive when possible
# This significantly reduces bandwidth and storage for backups
# Requires a common snapshot between source and target
incremental             yes


# --- Hooks ---
#
# NOTE: btrbk does NOT support exec hooks like snapshot_create_exec.
# The btrbk maintainer has explicitly rejected this feature due to security concerns.
# See: https://github.com/digint/btrbk/issues/58
#
# Snapshot cleanup solution:
#   Use btrbk-with-cleanup.sh wrapper script instead of running btrbk directly.
#   This script creates snapshots, runs snapshot-cleanup-hook.py on each one
#   (removing git-ignored files), then continues with the backup.
#
#   Usage:
#     ./btrbk-with-cleanup.sh -v -n run  # dry-run
#     ./btrbk-with-cleanup.sh -v run     # full backup with cleanup
#
# Alternative approaches (if not using the wrapper):
#   1. Run 'btrbk snapshot', manually clean snapshots, then 'btrbk run'
#   2. Use system-level hooks (e.g., systemd service hooks)
#   3. Use btrbk without cleanup (simplest, but snapshots will include git artifacts)

# --- SSH Configuration ---

# Backend for btrfs send/receive
# Options:
#   btrfs-progs-sudo: Run btrfs commands with sudo on remote (recommended for most setups)
#   btrfs-progs-btrbk: Use btrbk-ssh wrapper script (requires setup)
#   btrfs-progs-local: Local only, no SSH
backend                 btrfs-progs-sudo

# SSH user for remote connection
# The user must have sudo privileges for btrfs commands on the remote system
ssh_user                ubuntu

# SSH identity file
# When using SSH agent (e.g., 1Password SSH agent), leave this unset
# btrbk will automatically use SSH_AUTH_SOCK
# If not using SSH agent, uncomment and specify path to private key
#ssh_identity           ~/.ssh/id_rsa

# Compression
ssh_compression         yes # Options: gzip, pigz, bzip2, bzip3, xz, lz4, zstd, no
stream_compress         zstd
stream_compress_level   3  # Level 3 offers a good balance of speed and compression
stream_compress_threads default # Use multiple threads if available (supported by zstd)

# --- Backup Targets ---

# Backup configuration for /home/mjr and its subvolumes
# Each subvolume under /home/mjr is backed up independently
#
# IMPORTANT: All directories listed below MUST be btrfs subvolumes
# Use create-subvolumes.py to convert regular directories to subvolumes
# To verify: sudo btrfs subvolume show /home/mjr/<subvolume>
#
# Target format: ssh://hostname/absolute/path
# The hostname and path are defined in ../aws_connection.env:
#   BTRBK_AWS_HOST=<IP address>
#   BTRBK_AWS_PATH=/backup_volume/backups
# Format: ssh://${BTRBK_AWS_HOST}${BTRBK_AWS_PATH}/home/mjr
#
# Note: btrbk.conf doesn't support environment variable expansion.
# You must manually update the IP address below if it changes.
# Get current values with: source ../aws_connection.env && echo $BTRBK_AWS_HOST

volume /home/mjr
  # TODO:figure out env var interpolation or something
  target ssh://13.56.232.232/backup_volume/backups/

  subvolume code
  # subvolume Dygma TODO: move under code
  subvolume Documents
  # subvolume Desktop
  # subvolume Templates
  subvolume Pictures
  subvolume Public
  subvolume Videos
  # subvolume Music
  subvolume .config
  subvolume .dev_sculptor
  subvolume .sculptor
  subvolume .mozilla

# --- Common Operations ---
#
# Testing (always run dry-run first!):
#   btrbk -c btrfs/local/btrbk.conf -v -n run
#
# Create snapshots only (no remote backup):
#   btrbk -c btrfs/local/btrbk.conf -v snapshot
#
# Full backup (snapshot + send to remote):
#   btrbk -c btrfs/local/btrbk.conf -v run
#
# Backup specific subvolume only:
#   btrbk -c btrfs/local/btrbk.conf run /home/mjr/code
#
# List snapshots and backups:
#   btrbk -c btrfs/local/btrbk.conf list snapshots
#   btrbk -c btrfs/local/btrbk.conf list backups
#   btrbk -c btrfs/local/btrbk.conf list latest
#
# Show stats:
#   btrbk -c btrfs/local/btrbk.conf stats
#
# Clean up old snapshots (respecting retention policy):
#   btrbk -c btrfs/local/btrbk.conf clean
#
# --- Restoring from Backup ---
#
# 1. List available backups on remote:
#    ssh ubuntu@54.177.219.117 "sudo btrfs subvolume list /backup_volume/backups"
#
# 2. Receive a specific snapshot from remote:
#    ssh ubuntu@54.177.219.117 "sudo btrfs send /backup_volume/backups/home/mjr/code/code.20250101-1430" | \
#      sudo btrfs receive /tmp/restore/
#
# 3. Make the received snapshot writable (it's read-only by default):
#    sudo btrfs property set -ts /tmp/restore/code.20250101-1430 ro false
#
# 4. Copy or move files to final destination:
#    sudo rsync -av /tmp/restore/code.20250101-1430/ /home/mjr/code-restored/
#    # Or: sudo mv /tmp/restore/code.20250101-1430 /home/mjr/code-restored
#
# 5. Clean up:
#    sudo btrfs subvolume delete /tmp/restore/code.20250101-1430
#
# --- Troubleshooting ---
#
# Check if directories are subvolumes:
#   sudo btrfs subvolume show /home/mjr/code
#
# List all subvolumes:
#   sudo btrfs subvolume list /home
#
# Verify SSH access to remote:
#   ssh ubuntu@54.177.219.117 "sudo btrfs subvolume list /backup_volume"
#
# Test btrfs send/receive locally:
#   sudo btrfs subvolume snapshot -r /home/mjr/code /tmp/test-snapshot
#   sudo btrfs send /tmp/test-snapshot | sudo btrfs receive /tmp/test-receive/
#
# Debug btrbk with verbose output:
#   btrbk -c btrfs/local/btrbk.conf -v -l debug run
